[![headBanner](https://i.imgur.com/FrR9oGn.png)]()
# Project Insight
## Project Description
Our project Insight addresses one of the main issues faced by the hearing impaired community; which is that there exists a large majority of the population who cannot understand sign language, and this puts a strain on their ability to communicate with each other.

We plan to tackle this problem by developing a mobile application which facilitates image processing such that it can be used primarily by those who are not versed in sign language, so they can understand those who rely on American Sign Language (ASL). 
## Table of Contents
- [ Features ](#features)
- [ Installation and Running ](#i-r)
- [ Testing ](#testing)
- [ Application Instructions ](#instructions)
- [ References ](#references)

<a name="features"></a>
## Features
- Real-Time tracking as most other solutions are reliant on a previously stored form of media.
- Textâ€“To-Speech capabilities which allow for greater accessibility as another form of output delivery.
- Offline capability.
- Android support from as low as Android 7.0 Nougat.
- Support for both front and back cameras as modern devices have more than 1 camera modules.
- The ability to sign using single letters of the english alphabet.
- An extensive dictionary that covers the entire alphabet to create words/phrases.
- A recognition model using holistic hand landmarks to increase precision.

<a name="i-r"></a>
## Installation and Running

<a name="testing"></a>
## Testing

<a name="instructions"></a>
## Application Instructions

<a name="references"></a>
## References
- [TensorFlow Pose-Classification](https://www.tensorflow.org/lite/tutorials/pose_classification)
- [TensorFlow Classification](https://www.tensorflow.org/tutorials/images/classification)
- [TensorFlow Lite Image Classification](https://www.tensorflow.org/lite/examples/image_classification/overview)
- [Android TensorFlowLite Quickstart](https://www.tensorflow.org/lite/guide/android)
